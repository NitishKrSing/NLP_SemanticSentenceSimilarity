{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9iFdtD3Ulx7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load pre-trained Sentence-BERT model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Read data from two different sheets\n",
        "sheet1_df = pd.read_excel('Book1.xlsx', sheet_name='Sheet1')\n",
        "sheet2_df = pd.read_excel('Book1.xlsx', sheet_name='Sheet2')\n",
        "\n",
        "# Ensure that 'Sheet1' and 'Sheet2' have columns 'Sentence1' and 'Sentence2'\n",
        "# Adjust the column names based on your actual column names in the Excel sheets\n",
        "\n",
        "# Calculate similarity scores\n",
        "similarity_scores = []\n",
        "\n",
        "for index, (row1, row2) in enumerate(zip(sheet1_df.iterrows(), sheet2_df.iterrows())):\n",
        "    sentence1 = row1[1]['Sen']\n",
        "    sentence2 = row2[1]['HJ']\n",
        "\n",
        "    # Embed sentences and calculate cosine similarity\n",
        "    embeddings = model.encode([sentence1, sentence2], convert_to_tensor=True)\n",
        "    similarity = util.pytorch_cos_sim(embeddings[0], embeddings[1]).item()\n",
        "    similarity_scores.append(similarity)\n",
        "\n",
        "# Add similarity scores to a new column in one of the DataFrames (assuming they have the same length)\n",
        "sheet1_df['Similarity_Score'] = similarity_scores\n",
        "\n",
        "# Save the results back to Excel\n",
        "sheet1_df.to_excel('output_file.xlsx', index=False)\n"
      ]
    }
  ]
}